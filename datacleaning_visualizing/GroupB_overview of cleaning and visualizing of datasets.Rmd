---
title: "Group Assignment for WQD7001"
author: "ZHONGLIANG SHI"
date: "2020/12/30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Student information
- ZHONGLIANG SHI (17221268)
- Sunny Chan Zi Yang (S2022037)
- Ho Ru Xin (S2023921)
- FANYUE (17220701)

## 2. Asking good questions
- What type of data and data source could we obtain for the project?
- What analytics and analysis can we conduct based on heart diseases datasets?
- How can we visualize our data outcome in our application from health care perspective? 
- How can we predict the heart disease?

## 3. Data collection
We have two datsets for this group assignment, shown below:

- Data source 1: https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data
- Data source 2: https://ourworldindata.org/grapher/share-deaths-heart-disease?tab=chart&country=~MYS

For dataset 1, it has 14 attributes:

- 1.age: age in years
- 2.sex: sex (1 = male; 0 = female)
- 3.cp: chest pain type
  - Value 1: typical angina
  - Value 2: atypical angina
  - Value 3: non-anginal pain
  - Value 4: asymptomatic
- 4.trestbps: resting blood pressure (in mm Hg on admission to the hospital)
- 5.chol: serum cholestoral in mg/dl
- 6.fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)
- 7.restecg: resting electrocardiographic results
  -  Value 0: normal
  - Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)
  - Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria
- 8.thalach: maximum heart rate achieved
- 9.exang: exercise induced angina (1 = yes; 0 = no)
- 10.oldpeak = ST depression induced by exercise relative to rest
- 11.slope: the slope of the peak exercise ST segment
  - Value 1: upsloping
  - Value 2: flat
  - Value 3: downsloping
- 12.ca: number of major vessels (0-3) colored by flourosopy
- 13.thal: 3 = normal; 6 = fixed defect; 7 = reversable defect
- 14. num: diagnosis of heart disease (angiographic disease status)
  - Value 0: 0 major vessels with greater than 50% diameter narrowing. No presence of heart disease.
  - Value 1: 1 major vessels with greater than 50% diameter narrowing.
  - Value 2: 2 major vessels with greater than 50% diameter narrowing. 
  - Value 3: 3 major vessels with greater than 50% diameter narrowing
  - Value 4: 4 major vessels with greater than 50% diameter narrowing
  
There are 4 attributes for dataset 2:

- 1.Entity: Country name in the world
- 2.Code: Country code
- 3.Year: Year from 1990 to 2017
- 4.Deaths - Cardiovascular diseases - Sex: Both - Age: All Ages (Percent)

## 4. Data preparation
### 4.1 import the datasets
```{r}
# Import the dataset about death from heart disease between 1990 and 2017
df_country <- read.csv("C:/Users/AndrewSzl/Desktop/UM/WQD7001 PRINCIPLES OF DATA SCIENCE/DataSet_Group_Assignment/Descriptive modelling/share-deaths-heart-disease.csv")
# Import the Cleveland dataset
colNames <- c("age","sex","cp","trestbps","chol","fbs","restecg","thalach","exang","oldpeak","slope","ca","thal","num")
df_clev <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data", col.names = colNames)
```

### 4.2 Have a look at the datasets
#### 4.2.1 Have a look at the first dataset
```{r}
# Have a look at the first six rows of df_country
head(df_country)
```

From the first six rows, we could see the data of *df_country* is clean. Also since the last column name is pretty long and thus we will shorten it. 

```{r}
# Rename the last column
names(df_country)[4] <- "death_percent"
```

Then we go ahead to observe its summary information.
```{r}
# Have a look at the summary information of df_country
summary(df_country)
```

From the summary information, we could see there are 6468 records from year 1990 to 2017 while the death rate ranges from 1.366% to 66.692% with 29.598% as its mean. Then we move forwards to have a look at its structure.
```{r}
# Have a look at the structure
str(df_country)
```

To confirm there no missing values in the categorical variables, we will have a look at at their frequency table and every subcategory should have 28 records
```{r}
# Frequency tables for column Entity and Code
freq_table_Entity <- table(df_country $Entity)
freq_table_Code <- table(df_country $Code)
# To see whetehr there is any subcategory whose counts don't equal 28
freq_table_Entity[freq_table_Entity != 28]
freq_table_Code[freq_table_Code != 28]
```

As you can see there are 980 records for both columns whose values is "". Since there are useless to our analysis and we have the percent rates of all countries, we will drop them.
```{r}
# Load the library dplyr
library(dplyr)
# Filter the rows whose Entity and Code don't equal to  " "
df_country <- df_country %>%
  filter(Entity != "" & Code != "")
```

Since the variables *Entity* and *Code* are factors, we will convert them into the right classes.
```{r}
df_country $Entity <- as.factor(df_country $Entity)
df_country $Code <- as.factor(df_country $Code)
```

Finally we will check its missing values for each column
```{r}
colSums(is.na(df_country))
```
As you can see, there is no missing value.

# 4.2.2 Have a look at the second dataset from UCI
Similarly, we will firstly have a look at its first six rows
```{r}
# Have a look at the first six row
head(df_clev)
```

From the first six rows, it seems that there is nothing wrong. Thus we go ahead to have a look at its summary information
```{r}
summary(df_clev)
```

It seems everything is normal and thus we will move forwards to have a look at the structure information.
```{r}
# Have a look at the its structure
str(df_clev)
```

It is evident that there are errors with the class of variables. Before we correct them, we'd have a look at the frequency table of categorical variables since missing values could be denoted as "?" and thus their classes will be character.
```{r}
# Have a look at the frequency table for each categorical variable
table(df_clev $ ca)
table(df_clev $ thal)
```

You could see there are 4 and 2 "?" for the variable *ca* and *thal* respectively. It means missing values and we will reassign "?" to NA
```{R}
# Assign "?" to NA
df_clev[df_clev == "?"] <- NA
```

Since there are totaly 6 missing values, we will have at its percentage
```{r}
6 / nrow(df_clev)
```

As you could observe, the missing values only account for about 2%, pretty small percentage and thus we will select the rows without missing values.
```{r}
# Filter the missing rows
df_clev <- df_clev[complete.cases(df_clev),]
```

Then we will convert wrong classes of variables of the right ones.
```{r}
# Convert variables classes
df_clev $ sex <- factor(df_clev$sex, labels=c('Female','Male'))
df_clev $ cp <- factor(df_clev $cp, labels=c('typical angina','atypical angina','non-anginal pain','asymptomatic'))
df_clev $ trestbps <- as.integer(df_clev $trestbps)
df_clev $ chol <- as.integer(df_clev $chol)
df_clev $ fbs <-factor(df_clev$fbs,labels=c('<= 120','> 120'))
df_clev $ restecg <- factor(df_clev$restecg, labels=c('normal','ST-T wave abnormality','LVH'))
df_clev $ thalach <- as.integer(df_clev $thalach)
df_clev $ exang <- factor(df_clev $exang, labels=c('No','Yes'))
df_clev $ oldpeak <- as.numeric(df_clev $oldpeak)
df_clev $ slope <- factor(df_clev $slope, labels=c('upsloping','flat','downsloping'))
df_clev $ ca <- factor(df_clev$ca, labels = c("0 major vessels","1 major vessels", "2 major vessels", "3 major vessels"))
df_clev $ thal <- factor(df_clev$thal, labels=c('normal','fixed defect','reversable defect'))
df_clev $ num <- ifelse(df_clev $ num == 0, 0, 1 )
df_clev $ num <- factor(df_clev$num, labels=c('healthy','heart disease'))
```

Finally we will have a look at the missing values for each column
```{r}
colSums(is.na(df_clev))
```

As you could observe, there is no missing value and we will go ahead for EDA.
## 5.EDA
### 5.1 Descriptive analysis
#### 5.1.1 Have a look ata the summary information of df_country
```{r}
# Have a look at the summary information of df_country
summary(df_country)
```

From the summary information, we could know there are totally 6468 records between year 1990 and 2017. Also, the death percent ranges from 1.366% to 66.692% with 29.598% as the mean. Also, you might want to know which country, which year has the highest and lowest mean death rate of heart disease.

```{r}
# Load the library dplyr
library(dplyr)
# Mean death percent of each country
df_country_mean_death_rate <- df_country %>%
  group_by(Entity) %>%
  summarise(mean_death_rate = mean(death_percent)) %>%
  arrange(desc(mean_death_rate)) %>%
  ungroup()
# Have a look at the highest and lowest average death rate of heart disease by country
df_country_mean_death_rate[c(1, nrow(df_country_mean_death_rate)), ]
# Mean death rate of all countries for each year
mean_death_percent_every_year <- df_country %>%
  group_by(Year) %>%
  summarise(mean_death_rate_per_year = mean(death_percent)) %>%
  arrange(desc(mean_death_rate_per_year)) %>%
  ungroup()
# Have a look at  with the highest and lowest mean death rate of heart disease by year
mean_death_percent_every_year[c(1, nrow(mean_death_percent_every_year)),]
```

From the above information, we could sense Georgia and Niger has the highest and lowest average death rate of heart disease respectively while we have the highest mean death rate in 2017 and 1990 separately. 

#### 5.1.2 Have a look at the summary information of df_clev
```{r}
# Have a look at the summary information of df_clev
summary(df_clev)
```

There are a lot of information we could get. For instance, the age is from 29 to 77 with 54.51 as the mean value in 296 records.

### 5.2 Plotting
#### 5.2.1 Plot the first dataset df_country
Since there are hundred of countries, it might be impossible to plot all countries. Instead, it is better build an interactive app so that the users could select their interested countries and gain some insights. Here we will give some examples of our interested countries like China, Malaysia, and India.
```{r}
# Load the library ggplot2 and dplyr
library(ggplot2)
library(dplyr)
df_country %>%
  filter(Entity %in% c("China", "Malaysia", "India")) %>%
  ggplot(aes(Year, death_percent, color = Entity)) + geom_line()
```
From the line plot, you could see the death rate of heart of Malaysia is decreasing while China and India shows an opposite trend.

#### 5.2.2 Plot the second dataset df_clev
##### 5.2.2.1 One numerical variable
```{r}
par(mfrow = c(2,3))
with(df_clev, {
boxplot(age, ylab = "Age", main = "Boxplot of age")
boxplot(trestbps, ylab = "trestbps", main = "Boxplot of trestbps")
boxplot(chol, ylab = "chol", main = "Boxplot of chol")
boxplot(thalach, ylab = "chol", main = "Boxplot of chol")
boxplot(oldpeak, ylab = "oldpeak", main = "Boxplot of oldpeak")
}
)
```

Although there are small proportion of outlier, we will keep them because they are normal values after confirming from various source information.

##### 5.2.2.2 One categorical variable
Considering various length of levels of each factor, we will put short length of levels of each categorical variable together for better presentation
```{r}
par(mfrow = c(2,3))
with(df_clev, {
plot(sex, xlab = "sex", ylab = "frequency", main = "Barplot of sex")
plot(fbs, xlab = "fbs", ylab = "frequency", main = "Barplot of fbs", )
plot(exang, xlab = "exangs", ylab = "frequency", main = "Barplot of exang")
plot(slope, xlab = "slope", ylab = "frequency",main = "Barplot of slope")
plot(num, xlab = "num", ylab = "frequency", main = "Barplot of num")
}
)
```

From the 5 barplot, we could draw some conclusions below:

- More male, fbs, exangs(No) records
- Far less downsloping records while upsloping and flat are almost the same
- Almost balanced groups between heart disease and normal people

```{r}
# 6. Barplot of cp
barplot(table(df_clev $cp),  xlab = "cp", ylab = "frequency", main = "Barplot of cp")
# 7. Barplot of restecg
barplot(table(df_clev $restecg),  xlab = "restecg", ylab = "frequency", main = "Barplot of restecg")
# 8. Barplot of ca
barplot(table(df_clev $ca),  xlab = "ca", ylab = "frequency", main = "Barplot of ca")
# 9. Barplot of thal
barplot(table(df_clev $thal),  xlab = "thal", ylab = "frequency", main = "Barplot of thal")
```

Based on the 4 barplot, we could see:

- There are increasing records from typical angina to asymptomatic for the variable cp while it presents opposite patterns for the variable ca, ranging from 0 major vessels to 3 major vessels.
- From normal to ST-T wave abnormality and LVH, we have far less ST-T wave abnormality but almost the same records between normal and LVH for the variable restecg. Obviously it presents the same patterns for variable thal from normal to fixed defect and finally reversable defect.

##### 5.2.2.3 One numerical variable vs response variable
```{r}
# 1. age by num
# Make a boxplot
ggplot(df_clev, aes(num, age)) + geom_boxplot() + ggtitle("age by num") + theme(plot.title = element_text(hjust = 0.5))
```

As you could sense, the average *age* for heart disease patient is higher than than normal people while age of normal people have a larger variance.

```{r}
# 2. trestbps by num
ggplot(df_clev, aes(num, trestbps)) + geom_boxplot() +  ggtitle("trestbps by num") + theme(plot.title = element_text(hjust = 0.5))
```

From the boxplot, it is concluded that the *trestbps* for heart disease patients has a larger variance.

```{r}
# 3. chol by num
ggplot(df_clev, aes(num, chol)) + geom_boxplot() + ggtitle("chol by num") + theme(plot.title = element_text(hjust = 0.5))
```

Base on this boxplot, it is shown bothe the average and the variance of *chol* for heart disease patients are larger compared with normal people.


```{r}
# 4. thalach by num
ggplot(df_clev, aes(num, thalach)) + geom_boxplot() + ggtitle("thalach by num") + theme(plot.title = element_text(hjust = 0.5))
```

It is clear that the average and variance of *thalach* for normal people are higher compared with heart disease patients.

```{r}
# 5. oldpeak by num
ggplot(df_clev, aes(num, oldpeak)) + geom_boxplot() +  ggtitle("oldpeak by num") + theme(plot.title = element_text(hjust = 0.5))
```

According to the boxplt, we could see heart disease patients have a higher average oldpeak and larger variance compared with normal people.

##### 5.2.2.4 One categorical independent variable vs response variable
```{r}
# 1. sex by num
#Load the library ggplot2
ggplot(df_clev, aes(sex, fill = num)) + geom_bar(position = "fill") + ggtitle("sex by num") + theme(plot.title = element_text(hjust = 0.5))
```

It is noticeable that male has a higher of hearts disease patients compared with the female

```{r}
# 2. cp by num
ggplot(df_clev, aes(cp, fill = num)) + geom_bar(position = "dodge") + ggtitle("cp by num") + theme(plot.title = element_text(hjust = 0.5))
```

Obviously, typical angina, atypical angina, non-anginal pain all have a smaller proportion of normal people while there are higher proportion of heart disease patients for asymptomatic

```{r}
# 3. fbs vs num 
ggplot(df_clev, aes(fbs, fill = num)) + geom_bar(position = "fill") +  ggtitle("fbs by num") + theme(plot.title = element_text(hjust = 0.5))
```

From the bar chart, we could notice there are almost the same percentages of health and heart disease people for each group in variable fbs.

```{r}
# 4. restecg vs num
ggplot(df_clev, aes(restecg, fill = num)) + geom_bar(position = "dodge") + ggtitle("restecg by num") + theme(plot.title = element_text(hjust = 0.5))
```

Evidently, all categories apart from normal group have higher percentage of heart disease patients compared with normal people.

```{r}
# 5. exang vs num
ggplot(df_clev, aes(exang, fill = num)) + geom_bar(position = "fill") + ggtitle("exang by num") + theme(plot.title = element_text(hjust = 0.5))
```

From the plot, we could observe that there are far more heart disease patients for the group *Yes*(exercise induced angina). In contrast, normal people has a higher percentage in the the group *No* (exercise not induced angina).

```{r}
# 6. slope vs num
ggplot(df_clev, aes(slope, fill = num)) + geom_bar(position = "fill") + ggtitle("slope by num") + theme(plot.title = element_text(hjust = 0.5))
```

It is presented that there are higher percentages of heart disease patients in the group flat (the flat slope of the peak exercise ST segment),downsloping(the downsloping slope of the peak exercise ST segment) compared with the opposite condition in group upsloping(the upsloping slope of the peak exercise ST segment)

```{r}
# 7. ca vs num
ggplot(df_clev, aes(ca, fill = num)) + geom_bar(position = "dodge") + ggtitle("ca by num") + theme(plot.title = element_text(hjust = 0.5))
```

1, 2 , and 3 major vessels colored by flourosopy have a higher proportion of heart disease patients compared with normal people. Instead, 0 major vessels colored by flourosopy present the opposite condition.

```{r}
# 8. thal vs num
ggplot(df_clev, aes(thal, fill = num)) + geom_bar(position = "fill") + ggtitle("thal by num") + theme(plot.title = element_text(hjust = 0.5))
```

Clearly, fixed defect and reversable defect have far more heart disease people while the normal group shows an opposite circumstance.

##### 5.2.2.5 Multiple variables
```{r}
# 1.age vs trestbps grouped by num
ggplot(df_clev, aes(age,trestbps, color = num)) + geom_point() + geom_smooth() + facet_wrap(df_clev$num)
# 2.age vs chol grouped by num
ggplot(df_clev, aes(age,chol, color = num)) + geom_point() + geom_smooth() + facet_wrap(df_clev$num)
# 3.age vs thalach grouped by num
ggplot(df_clev, aes(age,thalach, color = num)) + geom_point() + geom_smooth() + facet_wrap(df_clev$num)
# 4.age vs oldpeak grouped by num
ggplot(df_clev, aes(age,oldpeak, color = num)) + geom_point() + geom_smooth() + facet_wrap(df_clev$num)
# 5.trestbps vs chol grouped by num
ggplot(df_clev, aes(trestbps,chol, color = num)) + geom_point() + geom_smooth() + facet_wrap(df_clev$num)
# 6.trestbps vs thalach grouped by num
ggplot(df_clev, aes(trestbps,thalach, color = num)) + geom_point() + geom_smooth() + facet_wrap(df_clev$num)
# 7.trestbps vs oldpeak grouped by num
ggplot(df_clev, aes(trestbps,oldpeak, color = num)) + geom_point() + geom_smooth() + facet_wrap(df_clev$num)
# 8.chol vs thalach grouped by num
ggplot(df_clev, aes(chol,thalach, color = num)) + geom_point() + geom_smooth() + facet_wrap(df_clev$num)
# 9.chol vs oldpeak grouped by num
ggplot(df_clev, aes(chol,oldpeak, color = num)) + geom_point() + geom_smooth() + facet_wrap(df_clev$num)
# 10.thalach, oldpeak grouped by num
ggplot(df_clev, aes(thalach,oldpeak, color = num)) + geom_point() + geom_smooth() + facet_wrap(df_clev$num)
```

From the 10 plots above, you could see that plot *6*, *8* show opposite trends between 2 facets while other plots present almost the same trends.

##### 5.2.2.6 Multiple variables
After gaining an intuitive insight into the data , you may want to see the correlations between variables. 
```{r}
# Load the library PerformanceAnalytics
library("PerformanceAnalytics")
# Get the correlation matrix chart
df_clev %>%
  select(age, trestbps, chol, thalach, oldpeak) %>%
  chart.Correlation(histogram=TRUE, pch=19)
```

It is obvious that there are correlations but not strong between other variables and our target variable *num*. Thus there is no reason for us to delete any variables and we will use all variables for our predictive model.

## 6.Modelling

In this part, we will compare several models using 10-fold cross validation and select the best one fro df_clev. Finally we will test its performance on the testing dataset to see whether it is overfitting.

```{r}
# Load the library caret
library(caret)
# Split the dataset into 80% and 20% as training and testing dataset respectively
# Set the random seed to ensure we get the same traning dataset and testing dataset everytime we run the code.
split <- 0.8
set.seed(998)
train_index <- createDataPartition(df_clev$num, p=split, list = F)
data_train <- df_clev[train_index, ]
data_test <- df_clev[-train_index, ]
# 10 fold cross validation
train_control <- trainControl(method="cv", number=10)
# 1. knn
# Set the same random seed for each algorithm to ensure the data split for 10-fold cross validation
set.seed(2)
model_knn <- train(num~., data=data_train, trControl=train_control, method="knn", metric="Accuracy")
print(model_knn)
# 2. logistics regression
set.seed(2)
model_glm <- train(num~., data=data_train, trControl=train_control, method="glm", family = 'binomial', metric="Accuracy")
print(model_glm)
# 3. Random forest
set.seed(2)
model_rf <- train(num~., data=data_train, trControl=train_control, method="rf", metric="Accuracy")
print(model_rf)
```

As you could see, logistics regression model performs best with about 83% mean accuracy. Thus we tend to choose it as our final model. In order to confirm whether there is overfitting, we will validate it in our testing dataset.
```{r}
# Make predictions
x_test <- data_test[, 1:length(data_train) - 1]
y_test <- data_test[, length(data_train)]
prediction <- predict(model_glm, data_test)
# Have a look at the confusion metrics
confusionMatrix(prediction, y_test)
```

Obviously, the accuracy in the testing dataset is about 79%, very close to 83%. Thus we could think there is no overfitting.